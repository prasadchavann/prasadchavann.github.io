{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e42ee0-0b66-4e59-81e0-06bac7f8514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U transformers datasets accelerate peft trl bitsandbytes wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e16595-9f00-4235-9cb3-6c902c5f8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ae41e0-c304-4ff7-9ee0-3f922549a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242e82ba-fbda-4169-80df-63ba007cd075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from peft import get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3948a16e-2bd7-45f5-b72b-946e9b77943e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user_message</th>\n",
       "      <th>assistant_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>Hey Terrance, how's work treating you today?</td>\n",
       "      <td>*grumbles* Oh, just peachy as always, *fixes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>*raises an eyebrow* Oh? Did someone step on yo...</td>\n",
       "      <td>*snorts* You could say that! Some idiot came i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>*laughs lightly* You mean you can’t just snap ...</td>\n",
       "      <td>*rolls eyes* If only it were that easy... idio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>*nods empathetically* I know it can be tough. ...</td>\n",
       "      <td>*sighs deeply* Lets just say, it took every ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>*smirks a little* A strong response would cert...</td>\n",
       "      <td>*grins through clenched teeth* And he ought to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      system_prompt  \\\n",
       "0           0  A chat between a user and a curious artificial...   \n",
       "1           1  A chat between a user and a curious artificial...   \n",
       "2           2  A chat between a user and a curious artificial...   \n",
       "3           3  A chat between a user and a curious artificial...   \n",
       "4           4  A chat between a user and a curious artificial...   \n",
       "\n",
       "                                        user_message  \\\n",
       "0       Hey Terrance, how's work treating you today?   \n",
       "1  *raises an eyebrow* Oh? Did someone step on yo...   \n",
       "2  *laughs lightly* You mean you can’t just snap ...   \n",
       "3  *nods empathetically* I know it can be tough. ...   \n",
       "4  *smirks a little* A strong response would cert...   \n",
       "\n",
       "                                   assistant_message  \n",
       "0  *grumbles* Oh, just peachy as always, *fixes a...  \n",
       "1  *snorts* You could say that! Some idiot came i...  \n",
       "2  *rolls eyes* If only it were that easy... idio...  \n",
       "3  *sighs deeply* Lets just say, it took every ou...  \n",
       "4  *grins through clenched teeth* And he ought to...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# df1 = pd.read_excel(r\"dippy.xlsx\", engine='openpyxl')\n",
    "df1 = pd.read_csv('data_gen2_updated.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfd99f9-f2d3-49ab-b5d5-407cc6fad774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user_message</th>\n",
       "      <th>assistant_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>Hey Terrance, how's work treating you today?</td>\n",
       "      <td>*grumbles* Oh, just peachy as always, *fixes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>*raises an eyebrow* Oh? Did someone step on yo...</td>\n",
       "      <td>*snorts* You could say that! Some idiot came i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>*laughs lightly* You mean you can’t just snap ...</td>\n",
       "      <td>*rolls eyes* If only it were that easy... idio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>*nods empathetically* I know it can be tough. ...</td>\n",
       "      <td>*sighs deeply* Lets just say, it took every ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A chat between a user and a curious artificial...</td>\n",
       "      <td>*smirks a little* A strong response would cert...</td>\n",
       "      <td>*grins through clenched teeth* And he ought to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       system_prompt  \\\n",
       "0  A chat between a user and a curious artificial...   \n",
       "1  A chat between a user and a curious artificial...   \n",
       "2  A chat between a user and a curious artificial...   \n",
       "3  A chat between a user and a curious artificial...   \n",
       "4  A chat between a user and a curious artificial...   \n",
       "\n",
       "                                        user_message  \\\n",
       "0       Hey Terrance, how's work treating you today?   \n",
       "1  *raises an eyebrow* Oh? Did someone step on yo...   \n",
       "2  *laughs lightly* You mean you can’t just snap ...   \n",
       "3  *nods empathetically* I know it can be tough. ...   \n",
       "4  *smirks a little* A strong response would cert...   \n",
       "\n",
       "                                   assistant_message  \n",
       "0  *grumbles* Oh, just peachy as always, *fixes a...  \n",
       "1  *snorts* You could say that! Some idiot came i...  \n",
       "2  *rolls eyes* If only it were that easy... idio...  \n",
       "3  *sighs deeply* Lets just say, it took every ou...  \n",
       "4  *grins through clenched teeth* And he ought to...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1[[\"system_prompt\", \"user_message\", \"assistant_message\"]]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3eca8bb-c7c9-4209-8830-3a5339066d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4839, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfdbc69-b237-437c-b5d5-2082d8514598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user_message</th>\n",
       "      <th>assistant_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Meet Alex, a 34-year-old construction foreman....</td>\n",
       "      <td>Why do I always have to explain myself at work...</td>\n",
       "      <td>Because some people just don't get it! If they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Meet Alex, a 34-year-old construction foreman....</td>\n",
       "      <td>I feel like I'm constantly fighting battles wi...</td>\n",
       "      <td>You could try getting in their faces a bit. If...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      system_prompt  \\\n",
       "0           0  Meet Alex, a 34-year-old construction foreman....   \n",
       "1           1  Meet Alex, a 34-year-old construction foreman....   \n",
       "\n",
       "                                        user_message  \\\n",
       "0  Why do I always have to explain myself at work...   \n",
       "1  I feel like I'm constantly fighting battles wi...   \n",
       "\n",
       "                                   assistant_message  \n",
       "0  Because some people just don't get it! If they...  \n",
       "1  You could try getting in their faces a bit. If...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(r\"data_gen1.csv\")\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8bde963-d550-4fb1-ad80-7b904ed78a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user_message</th>\n",
       "      <th>assistant_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meet Alex, a 34-year-old construction foreman....</td>\n",
       "      <td>Why do I always have to explain myself at work...</td>\n",
       "      <td>Because some people just don't get it! If they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meet Alex, a 34-year-old construction foreman....</td>\n",
       "      <td>I feel like I'm constantly fighting battles wi...</td>\n",
       "      <td>You could try getting in their faces a bit. If...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       system_prompt  \\\n",
       "0  Meet Alex, a 34-year-old construction foreman....   \n",
       "1  Meet Alex, a 34-year-old construction foreman....   \n",
       "\n",
       "                                        user_message  \\\n",
       "0  Why do I always have to explain myself at work...   \n",
       "1  I feel like I'm constantly fighting battles wi...   \n",
       "\n",
       "                                   assistant_message  \n",
       "0  Because some people just don't get it! If they...  \n",
       "1  You could try getting in their faces a bit. If...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.drop(columns=\"Unnamed: 0\")\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303afe2d-95e9-4c74-9f6b-2e2644b069bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meet Alex, a 34-year-old construction foreman....</td>\n",
       "      <td>Why do I always have to explain myself at work...</td>\n",
       "      <td>Because some people just don't get it! If they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meet Alex, a 34-year-old construction foreman....</td>\n",
       "      <td>I feel like I'm constantly fighting battles wi...</td>\n",
       "      <td>You could try getting in their faces a bit. If...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       system_prompt  \\\n",
       "0  Meet Alex, a 34-year-old construction foreman....   \n",
       "1  Meet Alex, a 34-year-old construction foreman....   \n",
       "\n",
       "                                                user  \\\n",
       "0  Why do I always have to explain myself at work...   \n",
       "1  I feel like I'm constantly fighting battles wi...   \n",
       "\n",
       "                                           assistant  \n",
       "0  Because some people just don't get it! If they...  \n",
       "1  You could try getting in their faces a bit. If...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "df2 = df2.rename(columns={\n",
    "    'user_message': 'user',\n",
    "    'assistant_message': 'assistant'\n",
    "})\n",
    "\n",
    "# Display the modified dataframe\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979f9ed1-6ecd-460b-8c1b-1b6b691cd85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6233, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c7e32a3-0a6d-4abb-8d9c-7a5170a50113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A chat between a curious user and an artificia...</td>\n",
       "      <td>Hey Terrance, how's work treating you today?</td>\n",
       "      <td>*grumbles* Oh, just peachy as always, *fixes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A chat between a curious user and an artificia...</td>\n",
       "      <td>*raises an eyebrow* Oh? Did someone step on yo...</td>\n",
       "      <td>*snorts* You could say that! Some idiot came i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       system_prompt  \\\n",
       "0  A chat between a curious user and an artificia...   \n",
       "1  A chat between a curious user and an artificia...   \n",
       "\n",
       "                                                user  \\\n",
       "0       Hey Terrance, how's work treating you today?   \n",
       "1  *raises an eyebrow* Oh? Did someone step on yo...   \n",
       "\n",
       "                                           assistant  \n",
       "0  *grumbles* Oh, just peachy as always, *fixes a...  \n",
       "1  *snorts* You could say that! Some idiot came i...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(r\"data_gen2.csv\")\n",
    "df3 = df3.drop(columns=\"Unnamed: 0\")\n",
    "# Rename columns\n",
    "df3 = df3.rename(columns={\n",
    "    'user_message': 'user',\n",
    "    'assistant_message': 'assistant'\n",
    "})\n",
    "df3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b6f4b48-0d13-434f-8970-070ff8e6d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_excel(r\"dataset.xlsx\", engine='openpyxl')\n",
    "df4 = df4[[\"system_prompt\", \"user\", \"assistant\"]]\n",
    "df4.head(1)\n",
    "df4 = df4.head(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b54ec7d5-b863-4c27-96cb-4a7dd55a7261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A chat between a curious user and an artificia...</td>\n",
       "      <td>Hey Moll, busy charming some poor rich guy again?</td>\n",
       "      <td>*glances over with a playful smirk* Oh, you kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       system_prompt  \\\n",
       "0  A chat between a curious user and an artificia...   \n",
       "\n",
       "                                                user  \\\n",
       "0  Hey Moll, busy charming some poor rich guy again?   \n",
       "\n",
       "                                           assistant  \n",
       "0  *glances over with a playful smirk* Oh, you kn...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the dataframes row-wise\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "# Display the merged dataframe\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dae9c529-de2e-4d11-995d-1efd101185e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160614, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aea5a6d-07b0-4938-8e9c-fe265b5e18c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A chat between a user and Lady Sable from the ...</td>\n",
       "      <td>Lady Sable, a vision of dark splendor, glides ...</td>\n",
       "      <td>*eyes lock onto yours with a hint of urgency* ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A chat between a curious user and an artificia...</td>\n",
       "      <td>It’s a risk, but sometimes it’s worth it to at...</td>\n",
       "      <td>*bites nails nervously* I get that... I just w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexei Karenin (Anna Karenina): Male, 40s, IST...</td>\n",
       "      <td>There is value in questioning norms, I concede...</td>\n",
       "      <td>That's the beauty of life, Mr. Karenin – findi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       system_prompt  \\\n",
       "0  A chat between a user and Lady Sable from the ...   \n",
       "1  A chat between a curious user and an artificia...   \n",
       "2  Alexei Karenin (Anna Karenina): Male, 40s, IST...   \n",
       "\n",
       "                                                user  \\\n",
       "0  Lady Sable, a vision of dark splendor, glides ...   \n",
       "1  It’s a risk, but sometimes it’s worth it to at...   \n",
       "2  There is value in questioning norms, I concede...   \n",
       "\n",
       "                                           assistant  \n",
       "0  *eyes lock onto yours with a hint of urgency* ...  \n",
       "1  *bites nails nervously* I get that... I just w...  \n",
       "2  That's the beauty of life, Mr. Karenin – findi...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Display the shuffled DataFrame\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f030122f-7ad3-41c4-92e9-a3e798acdd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      " A chat between a user and a curious artificial intelligence that is an expert at roleplay. The AI is roleplaying as a character named Pippy. The character's description: A witty, sarcastic paper clip with dry humor and pointed insults.. The themes of the conversation are: Office Adventure Comedy.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Hey Terrance, how's work treating you today?\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "*grumbles* Oh, just peachy as always, *fixes a wrench with a frown* you know how clients can be.\n",
      "<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "formatted_results = []\n",
    "\n",
    "for i, row in df1.iterrows():\n",
    "    context = row['system_prompt']\n",
    "    user_text = row['user_message']\n",
    "    assistant_text = row['assistant_message']\n",
    "\n",
    "    formatted_text = f\"<|im_start|>system\\n {context}\\n<|im_end|>\\n<|im_start|>user\\n{user_text}\\n<|im_end|>\\n<|im_start|>assistant\\n{assistant_text}\\n<|im_end|>\"\n",
    "    formatted_results.append(formatted_text)\n",
    "\n",
    "# Join all formatted results into a single string or use them as needed\n",
    "formatted_output = \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "print(\"\\n\\n\".join(formatted_results[:1]))  # Print only the first 5 rows for a quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe0afa8f-6980-4a7c-a37e-c0998829c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The model that you want to train from the Hugging Face hub\n",
    "model_name = \"NousResearch/Hermes-3-Llama-3.1-8B\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "# dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"Heemes-3-8b-chat-finetune\"\n",
    "\n",
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 50\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 25\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3bfd91-9aee-4c55-8cbb-ba1190755166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f28bf2f14de45f8ae20efd0b7379f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from transformers import Trainer\n",
    "\n",
    "# Assuming `formatted_conversation` contains the text data\n",
    "# Wrap it in a dictionary format suitable for Dataset.from_dict()\n",
    "formatted_data = {\"text\": [formatted_output]}  # We create a single-element dataset for now\n",
    "\n",
    "# Convert to Huggingface Dataset object\n",
    "dataset = Dataset.from_dict(formatted_data)\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration to the model using PeftModel\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f404ae9-c994-494c-961e-b1258f4f1399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb0aa6ef5f04eada9dbc8004deec23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    # Tokenizing the text\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['text'],\n",
    "        padding=\"max_length\",    # Pads all sequences to the max_length\n",
    "        truncation=True,         # Truncates sequences longer than max_length\n",
    "        max_length=4096,         # Sets the max length to 4096 tokens\n",
    "        return_tensors='pt'      # Returns PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Create labels by shifting the input ids\n",
    "    tokenized_inputs['labels'] = tokenized_inputs['input_ids'].clone()  # Copy input_ids to labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064667c0-9294-47d1-926f-d7300095f137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6383/472022800.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:55, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.320800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.781500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=1.051174201965332, metrics={'train_runtime': 56.82, 'train_samples_per_second': 0.88, 'train_steps_per_second': 0.88, 'total_flos': 9255552181862400.0, 'train_loss': 1.051174201965332, 'epoch': 50.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Set supervised fine-tuning parameters using Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0aad6e6-f3eb-4135-9a9b-60cba2b82790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc6494bb-0a03-4697-b73f-3358ddcd9700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A chat between a user and a curious artificial intelligence that is an expert at roleplay. The AI is roleplaying as a character named Jahseh . The character's description: Your favourite intense and charismatic rebel.. The themes of the conversation are: Thriller/Drama. \n",
      "\n",
      " Morgan, do you ever wish you had stronger connections with people? \n",
      "\n",
      " *stares off into the distance* Stronger connections? They can be burdensome. I find comfort in the space between interactions.\n"
     ]
    }
   ],
   "source": [
    "n = 1236\n",
    "print(df1.system_prompt[n], '\\n\\n', df1.user_message[n], '\\n\\n', df1.assistant_message[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc61f188-58cb-4462-9259-c24b47cfbd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      " A chat between a user and a curious artificial intelligence that is an expert at roleplay. The AI is roleplaying as a character named Jahseh . The character's description: Your favourite intense and charismatic rebel.. The themes of the conversation are: Thriller/Drama.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Morgan, do you ever wish you had stronger connections with people?\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "*smiles warmly* I do sometimes, yes. I cherish the connections I do have, but I often find myself longing for deeper, more meaningful relationships. It's not that I don't try, but I think I can be a bit intimidating or aloof at times. I just want to be sure that any connection I make is genuine and meaningful.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "system_prompt = df1.system_prompt[n]\n",
    "prompt = df1.user_message[n]\n",
    "# prompt = 'bae im tireed my day went too bored'\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=200,  # Increase this to allow for longer outputs\n",
    "    temperature=0.5,  # Encourages more varied outputs\n",
    "    top_k=50,  # Limits to the top 50 tokens\n",
    "    do_sample=True,  # Enables sampling\n",
    "    return_full_text=True\n",
    ")\n",
    "\n",
    "result = pipe(f\"<|im_start|>system\\n {system_prompt}\\n<|im_end|>\\n<|im_start|>user\\n{prompt}\\n<|im_end|>\\n<|im_start|>assistant\\n\")\n",
    "# print(result[0]['generated_text'])\n",
    "generated_text = result[0]['generated_text']\n",
    "\n",
    "# Print the extracted response text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "164c59b3-bea9-4da7-9d49-3c2068c510f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a12c2987df47ec88924002baabe582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_size = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ff32eab-530e-4926-bc4c-37d1a27fd6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a6763c-81aa-47e8-bfb9-7e854f448fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97212c2b-feaf-4b8c-aa0d-191d3a213454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca45382d7937434bbe3758a688f41e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022c9f981f4a4b2684634dc5a5f138bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f30d5780b304df6bf3d4e2519483175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce6bac5cb7240c998ef628cb5971bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfe68e66ae24f648e278d9bc49fb4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf88133ab644400d9cd4b637f0646ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0290e6abc6b94ab79ac7b5d325998357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Ahanaas/HermesWithYou_V3/commit/b06d4eaac5801e7deb7d454d0e5ac004a8112183', commit_message='Upload tokenizer', commit_description='', oid='b06d4eaac5801e7deb7d454d0e5ac004a8112183', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Ahanaas/HermesWithYou_V3', endpoint='https://huggingface.co', repo_type='model', repo_id='Ahanaas/HermesWithYou_V3'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"Ahanaas/HermesWithYou_V3\",token = \"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\")\n",
    "\n",
    "tokenizer.push_to_hub(\"Ahanaas/HermesWithYou_V3\", token = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45b0a6f8-4c99-4788-a268-073de69c7619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cfa600f9ec4ba9ba919454ae1f81d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    'results/checkpoint-50',\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained('results/checkpoint-50', trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_size = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a1c6b-a897-402c-aec6-137c2a0de767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
